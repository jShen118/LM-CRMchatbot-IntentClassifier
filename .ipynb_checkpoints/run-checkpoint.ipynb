{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run IntentClassifier.py\n",
    "%run batchtesting.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Access</th>\n",
       "      <th>Call</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>GRM</th>\n",
       "      <th>GRS</th>\n",
       "      <th>Mobile</th>\n",
       "      <th>Network</th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Hardware</th>\n",
       "      <th>None</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75-1</th>\n",
       "      <td>0.609</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.769</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75-2</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75-3</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg</th>\n",
       "      <td>0.592</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Access   Call  Frozen    GRM    GRS  Mobile  Network  Outlook  Rating  \\\n",
       "75-1   0.609  0.800   0.471  0.769  1.000   0.842    0.769    0.750   1.000   \n",
       "75-2   0.667  0.667   0.571  0.625  0.667   0.875    0.667    0.870   0.889   \n",
       "75-3   0.500  0.800   0.308  0.842  0.667   0.667    0.500    0.857   0.889   \n",
       "Avg    0.592  0.756   0.450  0.745  0.778   0.795    0.645    0.826   0.926   \n",
       "\n",
       "      Hardware   None    Avg  \n",
       "75-1     0.800  0.750  0.778  \n",
       "75-2     0.400  0.421  0.665  \n",
       "75-3     0.462  0.571  0.642  \n",
       "Avg      0.554  0.581  0.695  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#batchtest('Batch_Tests/75-1.json', verbose=False)\n",
    "#batchtest('Batch_Tests/75-2.json', verbose=False)\n",
    "#batchtest('Batch_Tests/75-3.json', verbose=False)\n",
    "files = ['Batch_Tests/75-1.json', 'Batch_Tests/75-2.json', 'Batch_Tests/75-3.json']\n",
    "runBatchtests(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTo Do:\\n*f-score calculations\\n*make Utterances class\\n*normalizations:\\n    stemming\\n    punctuation removal\\n*label None if None probability high enough (classification override)\\n*research decision_function vs predict vs predict_proba more https://scikit-learn.org/stable/modules/svm.html#scores-and-probabilities\\n*research vectorizers more, experiment w type and params\\nrunBatchtests function with pandas output\\nmatplotlib for runBatchtests\\nreview INCORRECTs and add to training data (not the verbatim tho that's cheating)\\n    make function in training.py to add newly labelled utterances to training.json\\npredictions json\\nentities https://docs.microsoft.com/en-us/azure/cognitive-services/luis/luis-concept-entity-types\\n    list entity\\n    regex entity\\n    prebuilt entity\\n    ML entity\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "To Do:\n",
    "*f-score calculations\n",
    "*make Utterances class\n",
    "*normalizations:\n",
    "    stemming\n",
    "    punctuation removal\n",
    "*label None if None probability high enough (classification override)\n",
    "*research decision_function vs predict vs predict_proba more https://scikit-learn.org/stable/modules/svm.html#scores-and-probabilities\n",
    "*research vectorizers more, experiment w type and params\n",
    "*runBatchtests function with pandas output\n",
    "matplotlib for runBatchtests\n",
    "review INCORRECTs and add to training data (not the verbatim tho that's cheating)\n",
    "    make function in training.py to add newly labelled utterances to training.json\n",
    "predictions json\n",
    "entities https://docs.microsoft.com/en-us/azure/cognitive-services/luis/luis-concept-entity-types\n",
    "    list entity\n",
    "    regex entity\n",
    "    prebuilt entity\n",
    "    ML entity\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNotes:\\nI noticed something very weird. It seems that my classifier is not deterministic, as in sometimes it produces\\noutput that is slightly different (few percentage pts) from previous output. This is weird because in theory\\nSVM is a deterministic algorithm, there should be no randomness to it. Will investigate further later\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Notes:\n",
    "I noticed something very weird. It seems that my classifier is not deterministic, as in sometimes it produces\n",
    "output that is slightly different (few percentage pts) from previous output. This is weird because in theory\n",
    "SVM is a deterministic algorithm, there should be no randomness to it. Will investigate further later\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
